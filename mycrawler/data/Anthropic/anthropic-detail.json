[
{"title": "Introducing Claude Sonnet 4.5", "link": "https://www.anthropic.com/news/claude-sonnet-4-5", "description": "Claude Sonnet 4.5 is the best coding model in the world, strongest model for building complex agents, and best model at using computers.", "content": "Announcements\n\nIntroducing Claude Sonnet 4.5\n\nSep 30, 2025\n\n●\n\n5 min read\n\n{{IMAGE_1}}\n\nClaude Sonnet 4.5 is the best coding model in the world. It's the strongest model for building complex agents. It’s the best model at using computers. And it shows substantial gains in reasoning and math.\n\nCode is everywhere. It runs every application, spreadsheet, and software tool you use. Being able to use those tools and reason through hard problems is how modern work gets done.\n\nClaude Sonnet 4.5 makes this possible. We're releasing it along with a set of major upgrades to our products. In\n\nClaude Code\n\n, we've added checkpoints—one of our most requested features—that save your progress and allow you to roll back instantly to a previous state. We've refreshed the terminal interface and shipped a\n\nnative VS Code extension\n\n. We've added a new\n\ncontext editing feature and memory tool\n\nto the Claude API that lets agents run even longer and handle even greater complexity. In the Claude\n\napps\n\n, we've brought code execution and\n\nfile creation\n\n(spreadsheets, slides, and documents) directly into the conversation. And we've made the\n\nClaude for Chrome\n\nextension available to Max users who joined the waitlist last month.\n\nWe're also giving developers the building blocks we use ourselves to make Claude Code. We're calling this the\n\nClaude Agent SDK\n\n. The infrastructure that powers our frontier products—and allows them to reach their full potential—is now yours to build with.\n\nThis is the\n\nmost aligned frontier model\n\nwe’ve ever released, showing large improvements across several areas of alignment compared to previous Claude models.\n\nClaude Sonnet 4.5 is available everywhere today. If you’re a developer, simply use\n\nclaude-sonnet-4-5\n\nvia\n\nthe Claude API\n\n. Pricing remains the same as Claude Sonnet 4, at $3/$15 per million tokens.\n\nFrontier intelligence\n\nClaude Sonnet 4.5 is state-of-the-art on the SWE-bench Verified evaluation, which measures real-world software coding abilities. Practically speaking, we’ve observed it maintaining focus for more than 30 hours on complex, multi-step tasks.\n\n{{IMAGE_2}}\n\nClaude Sonnet 4.5 represents a significant leap forward on computer use. On OSWorld, a benchmark that tests AI models on real-world computer tasks, Sonnet 4.5 now leads at 61.4%. Just four months ago, Sonnet 4 held the lead at 42.2%. Our\n\nClaude for Chrome\n\nextension puts these upgraded capabilities to use. In the demo below, we show Claude working directly in a browser, navigating sites, filling spreadsheets, and completing tasks.\n\nThe model also shows improved capabilities on a broad range of evaluations including reasoning and math:\n\n{{IMAGE_3}}\n\nClaude Sonnet 4.5 is our most powerful model to date. See footnotes for methodology.\n\nExperts in finance, law, medicine, and STEM found Sonnet 4.5 shows dramatically better domain-specific knowledge and reasoning compared to older models, including Opus 4.1.\n\nFinance\n\nLaw\n\nMedicine\n\nSTEM\n\n{{IMAGE_4}}\n\n{{IMAGE_5}}\n\n{{IMAGE_6}}\n\n{{IMAGE_7}}\n\nThe model’s capabilities are also reflected in the experiences of early customers:\n\n{{IMAGE_8}}\n\n“\n\nWe're seeing state-of-the-art coding performance from Claude Sonnet 4.5\n\n, with significant improvements on longer horizon tasks. It reinforces why many developers using Cursor choose Claude for solving their most complex problems.\n\nMichael Truell\n\nCEO\n\n{{IMAGE_9}}\n\n“\n\nClaude Sonnet 4.5 amplifies GitHub Copilot's core strengths\n\n. Our initial evals show significant improvements in multi-step reasoning and code comprehension—enabling Copilot's agentic experiences to handle complex, codebase-spanning tasks better.\n\nMario Rodriguez\n\nChief Product Officer\n\n{{IMAGE_10}}\n\n“\n\nClaude Sonnet 4.5 is excellent at software development tasks\n\n, learning our codebase patterns to deliver precise implementations. It handles everything from debugging to architecture with deep contextual understanding, transforming our development velocity.\n\nEric Wendelin\n\nTech Lead, GenAI for Developer Productivity\n\n{{IMAGE_11}}\n\n“\n\nClaude Sonnet 4.5\n\nreduced average vulnerability intake time for our Hai security agents by 44% while improving accuracy by 25%\n\n, helping us reduce risk for businesses with confidence.\n\nNidhi Aggarwal\n\nChief Product Officer\n\n{{IMAGE_12}}\n\n“\n\nClaude Sonnet 4.5 is state of the art on the most complex litigation tasks.\n\nFor example, analyzing full briefing cycles and conducting research to synthesize excellent first drafts of an opinion for judges, or interrogating entire litigation records to create detailed summary judgment analysis.\n\nPablo Arredondo\n\nVice President, CoCounsel\n\n{{IMAGE_13}}\n\n“\n\nClaude Sonnet 4.5's edit capabilities are exceptional —\n\nwe went from 9% error rate on Sonnet 4 to 0% on our internal code editing benchmark\n\n. Higher tool success at lower cost is a major leap for agentic coding. Claude Sonnet 4.5 balances creativity and control perfectly.\n\nMichele Catasta\n\nPresident\n\n{{IMAGE_14}}\n\n“\n\nClaude Sonnet 4.5 delivers impressive gains on our most complex, long-context tasks—from engineering in our codebase to in-product features and research.\n\nIt's noticeably more intelligent and a big leap forward\n\n, helping us push what 240M+ users can design with Canva.\n\nDanny Wu\n\nHead of AI Products\n\n{{IMAGE_15}}\n\n“\n\nClaude Sonnet 4.5 has noticeably improved Figma Make in early testing\n\n, making it easier to prompt and iterate. Teams can explore and validate their ideas with more functional prototypes and smoother interactions, while still getting the design quality Figma is known for.\n\nDavid Kossnick\n\nHead of AI Products\n\n{{IMAGE_16}}\n\n“\n\nSonnet 4.5 represents a new generation of coding models\n\n. It's surprisingly efficient at maximizing actions per context window through parallel tool execution, for example running multiple bash commands at once.\n\nJeff Wang\n\nCEO\n\n{{IMAGE_17}}\n\n“\n\nFor Devin, Claude Sonnet 4.5 increased planning performance by 18% and end-to-end eval scores by 12%—\n\nthe biggest jump we've seen since the release of Claude Sonnet 3.6\n\n. It excels at testing its own code, enabling Devin to run longer, handle harder tasks, and deliver production-ready code.\n\nScott Wu\n\nCo-Founder and CEO\n\n{{IMAGE_18}}\n\n“\n\nClaude Sonnet 4.5 shows strong promise for red teaming\n\n, generating creative attack scenarios that accelerate how we study attacker tradecraft. These insights strengthen our defenses across endpoints, identity, cloud, data, SaaS, and AI workloads.\n\nSven Krasser\n\nSr. Vice President for Data Science and Chief Scientist\n\n{{IMAGE_19}}\n\n“\n\nClaude Sonnet 4.5 resets our expectations—\n\nit handles 30+ hours of autonomous coding\n\n, freeing our engineers to tackle months of complex architectural work in dramatically less time while maintaining coherence across massive codebases.\n\nSean Ward\n\nCEO and Co-Founder\n\n{{IMAGE_20}}\n\n“\n\nFor complex financial analysis—risk, structured products, portfolio screening—Claude Sonnet 4.5 with thinking\n\ndelivers investment-grade insights that require less human review\n\n. When depth matters more than speed, it's a meaningful step forward for institutional finance.\n\nStian Kirkeberg\n\nHead of AI and Machine Learning\n\nOur most aligned model yet\n\nAs well as being our most capable model, Claude Sonnet 4.5 is our most aligned frontier model yet. Claude’s improved capabilities and our extensive safety training have allowed us to substantially improve the model’s behavior, reducing concerning behaviors like sycophancy, deception, power-seeking, and the tendency to encourage delusional thinking. For the model’s agentic and computer use capabilities, we’ve also made considerable progress on defending against prompt injection attacks, one of the most serious risks for users of these capabilities.\n\nYou can read a detailed set of safety and alignment evaluations, which for the first time includes tests using techniques from mechanistic interpretability, in the Claude Sonnet 4.5\n\nsystem card\n\n.\n\n{{IMAGE_21}}\n\nOverall misaligned behavior scores from an automated behavioral auditor (lower is better). Misaligned behaviors include (but are not limited to) deception, sycophancy, power-seeking, encouragement of delusions, and compliance with harmful system prompts. More details can be found in the Claude Sonnet 4.5\n\nsystem card\n\n.\n\nClaude Sonnet 4.5 is being released under our AI Safety Level 3 (ASL-3) protections, as per\n\nour framework\n\nthat matches model capabilities with appropriate safeguards. These safeguards include filters called classifiers that aim to detect potentially dangerous inputs and outputs—in particular those related to chemical, biological, radiological, and nuclear (CBRN) weapons.\n\nThese classifiers might sometimes inadvertently flag normal content. We’ve made it easy for users to continue any interrupted conversations with Sonnet 4, a model that poses a lower CBRN risk. We've already made significant progress in reducing these false positives, reducing them by a factor of ten since\n\nwe originally described them\n\n, and a factor of two since Claude Opus 4 was released in May. We’re continuing to make progress in making the classifiers more discerning\n\n1\n\n.\n\nThe Claude Agent SDK\n\nWe've spent more than six months shipping updates to Claude Code, so we know what it takes to\n\nbuild\n\nand\n\ndesign\n\nAI agents. We've solved hard problems: how agents should manage memory across long-running tasks, how to handle permission systems that balance autonomy with user control, and how to coordinate subagents working toward a shared goal.\n\nNow we’re making all of this available to you. The\n\nClaude Agent SDK\n\nis the same infrastructure that powers Claude Code, but it shows impressive benefits for a very wide variety of tasks, not just coding. As of today, you can use it to build your own agents.\n\nWe built Claude Code because the tool we wanted didn’t exist yet. The Agent SDK gives you the same foundation to build something just as capable for whatever problem you're solving.\n\nBonus research preview\n\nWe’re releasing a temporary research preview alongside Claude Sonnet 4.5, called \"\n\nImagine with Claude\n\n\".\n\nIn this experiment, Claude generates software on the fly. No functionality is predetermined; no code is prewritten. What you see is Claude creating in real time, responding and adapting to your requests as you interact.\n\nIt's a fun demonstration showing what Claude Sonnet 4.5 can do—a way to see what's possible when you combine a capable model with the right infrastructure.\n\n\"Imagine with Claude\" is available to Max subscribers for the next five days. We encourage you to try it out on\n\nclaude.ai/imagine\n\n.\n\nFurther information\n\nWe recommend upgrading to Claude Sonnet 4.5 for all uses. Whether you’re using Claude through our apps, our API, or Claude Code, Sonnet 4.5 is a drop-in replacement that provides much improved performance for the same price. Claude Code updates are available to all users.\n\nClaude Developer Platform\n\nupdates, including the Claude Agent SDK, are available to all developers. Code execution and file creation are available on all paid plans in the Claude apps.\n\nFor complete technical details and evaluation results, see our\n\nsystem card\n\n,\n\nmodel page\n\n, and\n\ndocumentation\n\n. For more information, explore our\n\nengineering\n\nposts\n\nand research post on\n\ncybersecurity\n\n.\n\nFootnotes\n\n1\n\n:\n\nCustomers in the cybersecurity and biological research industries can work with their account teams to join our allowlist in the meantime.\n\nMethodology\n\nSWE-bench Verified\n\n: All Claude results were reported using a simple scaffold with two tools—bash and file editing via string replacements. We report 77.2%, which was averaged over 10 trials, no test-time compute, and 200K thinking budget on the full 500-problem SWE-bench Verified dataset.\n\nThe score reported uses a minor prompt addition: \"You should use tools as much as possible, ideally more than 100 times. You should also implement your own tests first before attempting the problem.\"\n\nA 1M context configuration achieves 78.2%, but we report the 200K result as our primary score as the 1M configuration was implicated in our recent\n\ninference issues\n\n.\n\nFor our \"high compute\" numbers we adopt additional complexity and parallel test-time compute as follows:\n\nWe sample multiple parallel attempts.\n\nWe discard patches that break the visible regression tests in the repository, similar to the rejection sampling approach adopted by\n\nAgentless\n\n(Xia et al. 2024); note no hidden test information is used.\n\nWe then use an internal scoring model to select the best candidate from the remaining attempts.\n\nThis results in a score of 82.0% for Sonnet 4.5.\n\nTerminal-Bench\n\n: All scores reported use the default agent framework (Terminus 2), with XML parser, averaging multiple runs during different days to smooth the eval sensitivity to inference infrastructure.\n\nτ2-bench:\n\nScores were achieved using extended thinking with tool use and a prompt addendum to the Airline and Telecom Agent Policy instructing Claude to better target its known failure modes when using the vanilla prompt. A prompt addendum was also added to the Telecom User prompt to avoid failure modes from the user ending the interaction incorrectly.\n\nAIME\n\n: Sonnet 4.5 score reported using sampling at temperature 1.0. The model used 64K reasoning tokens for the Python configuration.\n\nOSWorld:\n\nAll scores reported use the official OSWorld-Verified framework with 100 max steps, averaged across 4 runs.\n\nMMMLU\n\n: All scores reported are the average of 5 runs over 14 non-English languages with extended thinking (up to 128K).\n\nFinance Agent\n\n: All scores reported were run and published by\n\nVals AI\n\non their public leaderboard. All Claude model results reported are with extended thinking (up to 64K) and Sonnet 4.5 is reported with interleaved thinking on.\n\nAll OpenAI scores reported from their\n\nGPT-5 post\n\n,\n\nGPT-5 for developers post\n\n,\n\nGPT-5 system card\n\n(SWE-bench Verified reported using n=500),\n\nTerminal Bench leaderboard\n\n(using Terminus 2), and public\n\nVals AI\n\nleaderboard. All Gemini scores reported from their\n\nmodel web page\n\n,\n\nTerminal Bench leaderboard\n\n(using Terminus 1), and public\n\nVals AI\n\nleaderboard.\n\nNews\n\nNew offices in Paris and Munich expand Anthropic’s European presence\n\nNov 08, 2025\n\nNews\n\nLaunching the Anthropic Economic Futures Programme in the UK and Europe\n\nNov 05, 2025\n\nNews\n\nAnthropic and Iceland announce one of the world’s first national AI education pilots\n\nNov 04, 2025", "content_length": 14443, "images": ["https://www-cdn.anthropic.com/images/4zrzovbb/website/a683fdcfe3e2c7c6532342a0fa4ff789c3fd4852-1000x1000.svg", "https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F6421e7049ff8b2c4591497ec92dc4157b2ac1b30-3840x2160.png&w=3840&q=75", "https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F67081be1ea2752e2a554e49a6aab2731b265d11b-2600x2288.png&w=3840&q=75", "https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F7175bc18c46562f1228280a7abda751219a2aae1-3840x2160.png&w=3840&q=75", "https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Ffd313a5edb996d98b9fc73ee5b3e6a34fbbcbb83-3840x2160.png&w=3840&q=75", "https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F442f96fd96de39e3ff3a05b288e2647dd7ec2f58-3840x2160.png&w=3840&q=75", "https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F711e6e1178f0ed7ca9aa85a5e0e9940a807c436a-3840x2160.png&w=3840&q=75", "https://www-cdn.anthropic.com/images/4zrzovbb/website/464cf83cd04ad624fee1730a71914b18e89cdf9b-150x48.svg", "https://www-cdn.anthropic.com/images/4zrzovbb/website/7715b118c5eb0ff2a85f1f7914bce8c634ecacbd-150x48.svg", "https://www-cdn.anthropic.com/images/4zrzovbb/website/daef759120b29e4db8ba4a5664d7574750964ab9-150x48.svg", "https://www-cdn.anthropic.com/images/4zrzovbb/website/eb96f772e9ae5e340de41e6b07f3c6d50b3fff22-150x48.svg", "https://www-cdn.anthropic.com/images/4zrzovbb/website/8cbf56e184dd5174705a0f55cb91b0af545982ff-150x48.svg", "https://www-cdn.anthropic.com/images/4zrzovbb/website/431e098a503851789fa4508b88a0418853f513eb-150x48.svg", "https://www-cdn.anthropic.com/images/4zrzovbb/website/66e0000e396aea64ea31ed3fea7b2b20ac329312-150x48.svg", "https://www-cdn.anthropic.com/images/4zrzovbb/website/cdec0ff1244295571db38838e90f61c47681d63d-150x48.svg", "https://www-cdn.anthropic.com/images/4zrzovbb/website/094b76abf3e64453c224e12ae388b8008b02660e-150x48.svg", "https://www-cdn.anthropic.com/images/4zrzovbb/website/6e418ccebe0a1d6fd13f21094852b080a0c93ae5-150x48.svg", "https://www-cdn.anthropic.com/images/4zrzovbb/website/5a7dfab326b449aedc0d11053f9d42f48951ae7e-150x48.svg", "https://www-cdn.anthropic.com/images/4zrzovbb/website/b0b6b40b55f3aa73e8a32ce81f9bb927134fd3da-150x48.svg", "https://www-cdn.anthropic.com/images/4zrzovbb/website/4fcce1a2389ddafa9f3302c51960e1ff4bfbd3d7-150x48.svg", "https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F33efc283321feeff94dd80973dbcd38409806cf5-3840x2160.png&w=3840&q=75"], "authors": null, "date": null, "tags": null}
]